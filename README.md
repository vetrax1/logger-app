# LoggerBuddy

> A tiny, production-minded multi-service demo that proves the full DevOps flow: **UI â†’ API â†’ Database**, packaged with **Docker Compose**, designed to be **reproducible**, **debuggable**, and **ready to grow into Jenkins CI + GitOps (Argo CD) + AKS**.

---

## âœ¨ What this project is

LoggerBuddy is a simple â€œlog messageâ€ app used as a learning and portfolio-ready DevOps artifact.

It demonstrates:

* **Multi-service architecture** (frontend + backend + PostgreSQL)
* **Service discovery** via Docker Compose DNS (service names)
* **Config injection** via environment variables
* **Persistence** via named volumes
* **Reliability** with health checks and startup ordering
* **Operability** with clear debug commands and runbook-style docs

---

## ğŸ§  Architecture

### High-level flow

1. **User** opens the UI in the browser.
2. UI sends an HTTP request to the **Backend API**.
3. Backend stores and retrieves logs from **PostgreSQL**.
4. Database data persists on a **named volume**.

### Architecture diagram (sketch)

```text
                  (User)
                    |
                    | 1) HTTP GET
                    v
          +---------------------+
          |  Frontend (NGINX)   |
          |  Static HTML UI     |
          +---------------------+
                    |
                    | 2) HTTP POST /log
                    |    HTTP GET  /recent
                    v
          +---------------------+
          |  Backend (Flask API)|
          |  Business logic +   |
          |  SQL queries        |
          +---------------------+
                    |
                    | 3) TCP 5432 (Postgres protocol)
                    v
          +---------------------+
          |  PostgreSQL (DB)    |
          |  Table: logs        |
          +---------------------+
                    |
                    | 4) Persistent storage
                    v
          +---------------------+
          |  Volume: pgdata     |
          |  /var/lib/postgresql|
          |  /data              |
          +---------------------+

      * All services communicate on the Compose network: loggernet
      * DNS inside the network resolves service names (e.g., `db`)
```

---

## ğŸ“ Repository structure

```text
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app.py
â””â”€â”€ db/
    â””â”€â”€ init.sql
```

---

## âœ… Prerequisites

* Docker Engine installed
* Docker Compose v2 available (`docker compose`)

Verify:

```bash
docker --version
docker compose version
```

---

## ğŸš€ Quickstart (Run in 3 minutes)

### 1) Configure environment variables

Copy the example file:

```bash
cp .env.example .env
```

Update `.env` (choose a strong password):

```env
DB_PASSWORD=ChangeMeStrongPassword
```

### 2) Build and run

```bash
docker compose up -d --build
```

### 3) Open the app

* Frontend UI: `http://localhost:8080`
* Backend API: `http://localhost:5000`

---

## ğŸ”Œ API Endpoints

### Health checks

* `GET /health` â†’ confirms API is alive
* `GET /db-check` â†’ confirms API can connect to Postgres and execute a query

Example:

```bash
curl http://localhost:5000/health
curl http://localhost:5000/db-check
```

### Logging

* `POST /log` â†’ store a message

```bash
curl -X POST -d "message=Hello LoggerBuddy" http://localhost:5000/log
```

### Read logs

* `GET /recent` â†’ returns the last 10 log entries (most recent first)

```bash
curl http://localhost:5000/recent
```

---

## ğŸ—„ï¸ Database

### Schema

Postgres initializes a simple `logs` table on first boot (via `db/init.sql`):

```sql
CREATE TABLE IF NOT EXISTS logs (
  id SERIAL PRIMARY KEY,
  message TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### Under the hood: initialization behavior

* The Postgres container executes SQL files inside `/docker-entrypoint-initdb.d/` **only when the data directory is empty**.
* Because we mount a named volume (`pgdata`), that initialization runs **once** per volume lifecycle.

---

## ğŸ’¾ Persistence (prove your data survives restarts)

### Persistence test

1. Add a few logs
2. Stop services

```bash
docker compose down
```

3. Start services again

```bash
docker compose up -d
```

4. Confirm logs still exist

```bash
curl http://localhost:5000/recent
```

### âš ï¸ Destroying data intentionally (dev-only)

```bash
docker compose down -v
```

This removes containers **and** volumes.

---

## ğŸ” Observability (how to inspect whatâ€™s happening)

### View running services

```bash
docker compose ps
```

### Tail logs

```bash
docker compose logs -f backend
```

### Exec into containers

```bash
docker compose exec backend sh
```

### Query database directly (gold standard verification)

```bash
docker compose exec db psql -U loggeruser -d loggerdb -c "SELECT * FROM logs ORDER BY id DESC LIMIT 5;"
```

---

## ğŸ§¯ Troubleshooting (fast fixes)

### 1) Backend canâ€™t connect to DB

**Symptoms:** `/db-check` fails or backend logs show connection errors.

**Fix:**

* Confirm DB is healthy:

```bash
docker compose ps
```

* View DB logs:

```bash
docker compose logs db
```

* Verify DNS resolution from backend:

```bash
docker compose exec backend sh -c "getent hosts db || nslookup db"
```

### 2) `init.sql` didnâ€™t run / table missing

If the `pgdata` volume already existed, Postgres will not re-run init scripts.

**Dev reset:**

```bash
docker compose down -v
docker compose up -d --build
```

### 3) Password auth failed

* Confirm `.env` exists and matches the compose variables.
* Restart the stack:

```bash
docker compose down
docker compose up -d
```

---

## ğŸ” Security notes (lab-safe habits)

* `.env` is not committed (secrets stay local).
* DB is **not** exposed to the host by default (no `5432:5432` mapping).
* In production you would store secrets in a manager (Azure Key Vault) and inject them securely.

---

## ğŸ§­ Roadmap (where this goes next)

This project is intentionally designed to grow into a full DevOps delivery chain:

1. **Jenkins CI**

   * checkout â†’ lint â†’ test â†’ build images â†’ scan images
2. **Registry**

   * Docker Hub now â†’ **Azure Container Registry (ACR)** later
3. **GitOps (Argo CD)**

   * Jenkins updates GitOps repo image tag â†’ Argo CD syncs to AKS
4. **AKS deployment**

   * Helm/Kustomize manifests, Ingress, TLS, autoscaling


---

## ğŸ™Œ Credits

Built as part of the **#100DaysOfDevOps** journey under **TechdotSam**.
 
